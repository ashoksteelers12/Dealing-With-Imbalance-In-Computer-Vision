{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x111011ab0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser(description='Imbalanced MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--nrow', type=int, default=5,\n",
    "                    help='rows of example')\n",
    "parser.add_argument('--ncol', type=int, default=10,\n",
    "                    help='columns of example')\n",
    "parser.add_argument('-f')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "imbalanced_linear_train_dataset = torch.load('imbalanced_linear_train_dataset.pt')\n",
    "imbalanced_linear_train_loader = torch.utils.data.DataLoader(imbalanced_linear_train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "imbalanced_step_train_dataset = torch.load('imbalanced_step_train_dataset.pt')\n",
    "imbalanced_step_train_loader = torch.utils.data.DataLoader(imbalanced_step_train_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "test_dataset = torch.load('test_dataset.pt')\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def show_mnist(arr, nrow=args.nrow, ncol=args.ncol, figsize=None):\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (ncol, nrow)\n",
    "        \n",
    "    f, a = plt.subplots(nrow, ncol, figsize=figsize)\n",
    "    \n",
    "    def _do_show(the_figure, the_array):\n",
    "        the_figure.imshow(the_array)\n",
    "        the_figure.axis('off')\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            _do_show(a[i][j], np.reshape(arr[i * ncol + j], (28, 28)))\n",
    "            \n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.draw()\n",
    "    plt.savefig('examples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(6272, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6272, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x129ebf120>\n",
      "8\n",
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 6272])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# Convolution 1: 16 Kernels\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# Convolution 1 Bias: 16 Kernels\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# Convolution 2: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Convolution 2 Bias: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "print(list(model.parameters())[4].size())\n",
    "\n",
    "# Fully Connected Layer Bias\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Accuracy: 77\n",
      "Iteration: 1000. Accuracy: 86\n",
      "Iteration: 1500. Accuracy: 90\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(imbalanced_linear_train_loader):\n",
    "        images = images.requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images = images.requires_grad_()\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            print('Iteration: {}. Accuracy: {}'.format(iter, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 1000 Images: 95.37\n"
     ]
    }
   ],
   "source": [
    "# https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-in-pytorch/\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "correct_vals = []\n",
    "auroc_scores = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct_vals.append((predicted == labels).sum().item())\n",
    "        accuracy = (correct / total) * 100\n",
    "        \n",
    "        sm = nn.Softmax(dim = 1)\n",
    "        prob = sm(outputs)\n",
    "        preds = np.argmax(prob, axis = 1)\n",
    "        arc = roc_auc_score(labels, prob, multi_class = 'ovr', average = 'macro')\n",
    "        auroc_scores.append(arc)\n",
    "\n",
    "    print('Accuracy on 1000 Images: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(correct_vals)):\n",
    "    correct_vals[i] = correct_vals[i] * .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN_linear.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from joblib import dump, load\n",
    "\n",
    "#dump(model, 'CNN_linear.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUROC: 0.9985814971940419\n"
     ]
    }
   ],
   "source": [
    "avg_auroc = sum(auroc_scores) / len(auroc_scores)\n",
    "print('Average AUROC: {}'.format(avg_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "plt.bar(x_axis, avg_auroc)\n",
    "plt.title('Linear CNN AUROC Scores')\n",
    "plt.xlabel('Images')\n",
    "plt.ylabel('Score')\n",
    "plt.savefig('auroc_linear_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Distribution of classes in linear imbalanced dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(imbalanced_linear_train_loader.dataset.train_labels, return_counts=True)\n",
    "num_classes = 10\n",
    "classe_labels = range(num_classes)\n",
    "ax.bar(classe_labels, counts)\n",
    "ax.set_xticks(classe_labels)\n",
    "plt.savefig('dist linear.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Distribution of classes in step imbalanced dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(imbalanced_step_train_loader.dataset.train_labels, return_counts=True)\n",
    "num_classes = 10\n",
    "classe_labels = range(num_classes)\n",
    "ax.bar(classe_labels, counts)\n",
    "ax.set_xticks(classe_labels)\n",
    "plt.savefig('dist step.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "for data, _ in imbalanced_linear_train_loader:\n",
    "    show_mnist(data)\n",
    "    break\n",
    "    \n",
    "for data, _ in imbalanced_step_train_loader:\n",
    "    show_mnist(data)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
