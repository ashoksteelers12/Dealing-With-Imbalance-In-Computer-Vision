{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import argparse\n",
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x121457950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser(description='Imbalanced MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--nrow', type=int, default=5,\n",
    "                    help='rows of example')\n",
    "parser.add_argument('--ncol', type=int, default=10,\n",
    "                    help='columns of example')\n",
    "parser.add_argument('-f')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "imbalanced_linear_train_dataset = torch.load('imbalanced_linear_train_dataset.pt')\n",
    "imbalanced_linear_train_loader = torch.utils.data.DataLoader(imbalanced_linear_train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "imbalanced_step_train_dataset = torch.load('imbalanced_step_train_dataset.pt')\n",
    "imbalanced_step_train_loader = torch.utils.data.DataLoader(imbalanced_step_train_dataset, batch_size=args.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "test_dataset = torch.load('test_dataset.pt')\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def show_mnist(arr, nrow=args.nrow, ncol=args.ncol, figsize=None):\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (ncol, nrow)\n",
    "        \n",
    "    f, a = plt.subplots(nrow, ncol, figsize=figsize)\n",
    "    \n",
    "    def _do_show(the_figure, the_array):\n",
    "        the_figure.imshow(the_array)\n",
    "        the_figure.axis('off')\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            _do_show(a[i][j], np.reshape(arr[i * ncol + j], (28, 28)))\n",
    "            \n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.draw()\n",
    "    plt.savefig('examples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, 1, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(6272, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=6272, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x12b4d4eb0>\n",
      "8\n",
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([64, 6272])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "\n",
    "print(len(list(model.parameters())))\n",
    "\n",
    "# Convolution 1: 16 Kernels\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# Convolution 1 Bias: 16 Kernels\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# Convolution 2: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Convolution 2 Bias: 32 Kernels with depth = 16\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "print(list(model.parameters())[4].size())\n",
    "\n",
    "# Fully Connected Layer Bias\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Accuracy: 84\n",
      "Iteration: 1000. Accuracy: 89\n",
      "Iteration: 1500. Accuracy: 92\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(imbalanced_step_train_loader):\n",
    "        images = images.requires_grad_()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images = images.requires_grad_()\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            print('Iteration: {}. Accuracy: {}'.format(iter, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 1000 Images: 96.98\n"
     ]
    }
   ],
   "source": [
    "# https://adventuresinmachinelearning.com/convolutional-neural-networks-tutorial-in-pytorch/\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "correct_vals = []\n",
    "auroc_scores = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        correct_vals.append((predicted == labels).sum().item())\n",
    "        accuracy = (correct / total) * 100\n",
    "        \n",
    "        sm = nn.Softmax(dim = 1)\n",
    "        prob = sm(outputs)\n",
    "        preds = np.argmax(prob, axis = 1)\n",
    "        arc = roc_auc_score(labels, prob, multi_class = 'ovr', average = 'macro')\n",
    "        auroc_scores.append(arc)\n",
    "\n",
    "    print('Accuracy on 1000 Images: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(correct_vals)):\n",
    "    correct_vals[i] = correct_vals[i] * .10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN_step.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from joblib import dump, load\n",
    "\n",
    "#dump(model, 'CNN_step.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUROC: 0.9993784229061411\n"
     ]
    }
   ],
   "source": [
    "avg_auroc = sum(auroc_scores) / len(auroc_scores)\n",
    "print('Average AUROC: {}'.format(avg_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "plt.bar(x_axis, avg_auroc)\n",
    "plt.title('Linear CNN AUROC Scores')\n",
    "plt.xlabel('Images')\n",
    "plt.ylabel('Score')\n",
    "plt.savefig('auroc_step_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Distribution of classes in linear imbalanced dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(imbalanced_linear_train_loader.dataset.train_labels, return_counts=True)\n",
    "num_classes = 10\n",
    "classe_labels = range(num_classes)\n",
    "ax.bar(classe_labels, counts)\n",
    "ax.set_xticks(classe_labels)\n",
    "plt.savefig('dist linear.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Distribution of classes in step imbalanced dataset:')\n",
    "fig, ax = plt.subplots()\n",
    "_, counts = np.unique(imbalanced_step_train_loader.dataset.train_labels, return_counts=True)\n",
    "num_classes = 10\n",
    "classe_labels = range(num_classes)\n",
    "ax.bar(classe_labels, counts)\n",
    "ax.set_xticks(classe_labels)\n",
    "plt.savefig('dist step.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "for data, _ in imbalanced_linear_train_loader:\n",
    "    show_mnist(data)\n",
    "    break\n",
    "    \n",
    "for data, _ in imbalanced_step_train_loader:\n",
    "    show_mnist(data)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
